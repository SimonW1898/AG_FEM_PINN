{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1796e9d6",
   "metadata": {},
   "source": [
    "# Solve Problem 1: Helmholtz Equation without potential with PINN\n",
    "\n",
    "\n",
    "### Equation:\n",
    "$$\n",
    "i \\partial_t u(x,t) = - \\Delta u(x,t) + V(x,t) u(x,t), \\quad x \\in \\Omega, \\ t > 0, \\\\\n",
    "\\quad \\partial_t u(x,0) = u_0(x), \\quad x \\in \\Omega, \\\\\n",
    "\\quad u(x,t) = g(x,t), \\quad x \\in \\Gamma_D, t>0, \\\\\n",
    "\\quad \\partial_n u(x,t) = h(x,t), \\quad x \\in \\Gamma_N, t> 0.\n",
    "$$\n",
    "where the potential $V(x,t)$ is zero, i.e., $V(x,t) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3ee2d",
   "metadata": {},
   "source": [
    "## Formulate the PINN loss function:\n",
    "Starting with the classical PINN approach, we define the residual function of the PDE as:\n",
    "$$\n",
    "R(x,t) = i \\partial_t u(x,t) - \\Delta u(x,t) - V(x,t) u(x,t), \\quad x \\in \\Omega, \\ t > 0.\n",
    "$$\n",
    "The goal is to minimize this residual, for that we add into the loss the residual loss, initial condition loss, and boundary condition loss:\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\mathcal{L}_{\\text{PDE}}(\\theta) + \\mathcal{L}_{\\text{IC}}(\\theta) + \\mathcal{L}_{\\text{BC}}(\\theta),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mathcal{L}_{\\text{PDE}}(\\theta) = \\frac{1}{N_{\\text{PDE}}} \\sum_{i=1}^{N_{\\text{PDE}}} R(x_i, t_i; \\theta)^2,\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L}_{\\text{IC}}(\\theta) = \\frac{1}{N_{\\text{IC}}} \\sum_{i=1}^{N_{\\text{IC}}} (u(x_i, 0; \\theta) - u_0(x_i))^2,\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L}_{\\text{BC}}(\\theta) = \\frac{1}{N_{\\text{BC}}} \\sum_{i=1}^{N_{\\text{BC}}} (u(x_i, t_i; \\theta) - g(x_i, t_i))^2 + \\frac{1}{N_{\\text{BC}}} \\sum_{i=1}^{N_{\\text{BC}}} (\\partial_n u(x_i, t_i; \\theta) - h(x_i, t_i))^2.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0b95c",
   "metadata": {},
   "source": [
    "## Initial and Boundary Conditions:\n",
    "The initial condition is given by:\n",
    "$$\n",
    "u(x,0) = \\sin(\\pi x_1)\\sin(\\pi x_2), \\quad x \\in \\Omega,\n",
    "$$\n",
    "where $\\Omega = [0,1]^2$.\n",
    "The boundary conditions are homogeneous Dirichlet boundary conditions:\n",
    "$$\n",
    "u(x,t) = 0, \\quad \\forall x \\in \\partial \\Omega,\\; t > 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f8ad62",
   "metadata": {},
   "source": [
    "## Layout of the PINN:\n",
    "The handling of complex numbers in the PINN is done by separating the real and imaginary parts of the solution, meaning the output of the PINN has to be a vector of the form:\n",
    "$$\n",
    "u(x,t) = \\begin{pmatrix}\n",
    "\\text{Re}(u(x,t)) \\\\\n",
    "\\text{Im}(u(x,t))\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "The Input are then sampling points in the domain $\\Omega$ and time $t$, i.e., the input are then triples of the form $(x_1, x_2, t)$, where $x_1, x_2 \\in [0,1]$ and $t > 0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01eb2e2",
   "metadata": {},
   "source": [
    "## Define the PINN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e301be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc7ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, n_hidden = 64, *args, **kwargs):\n",
    "        \"\"\" \n",
    "        PINN model for solving PDEs.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linear1 = nn.Linear (3,n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear3 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear4 = nn.Linear(n_hidden,2)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass through the network.\n",
    "        Input:\n",
    "            x: input tensor of shape (N, 3)\n",
    "        Output:\n",
    "            output: tensor of shape (N, 2) (Real and Imaginary parts of the solution)\n",
    "        \"\"\"\n",
    "        x = self.activation(self.linear1(x))\n",
    "        x = self.activation(self.linear2(x))\n",
    "        x = self.activation(self.linear3(x))\n",
    "        output = self.linear4(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c55ddb",
   "metadata": {},
   "source": [
    "### Define Derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7df1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_gradients(model, x):\n",
    "    \"\"\"\n",
    "    Compute gradients of the model output with respect to the input.\n",
    "    Input:\n",
    "        model: PINN model\n",
    "        x: input tensor of shape (N, 3)\n",
    "    Output:\n",
    "        gradients: tensor of shape (N, 2, 3) containing gradients\n",
    "        with respect to Re(u) and Im(u) for each input dimension (x1, x2, t)\n",
    "    \"\"\"\n",
    "    output = model(x)  # shape (N, 2)\n",
    "    grads = []\n",
    "    for i in range(output.shape[1]):  # for Re(u), Im(u)\n",
    "        grad = torch.autograd.grad(\n",
    "            outputs=output[:, i],\n",
    "            inputs=x,\n",
    "            grad_outputs=torch.ones_like(output[:, i]),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]  # shape (N, 3)\n",
    "        grads.append(grad)\n",
    "    gradients = torch.stack(grads, dim=1)  # shape (N, 2, 3)\n",
    "    return gradients\n",
    "\n",
    "def second_derivative(y,x,idx):\n",
    "    \"\"\" \n",
    "    Compute the second derivatives\n",
    "    needs special handling because the model has real and imaginary parts which needs to be handled separately\n",
    "    Input:\n",
    "        y: output tensor of shape (N, 2) (Real and Imaginary parts)\n",
    "        x: input tensor of shape (N, 3)\n",
    "        idx: index for which second derivative is computed (0 for x1, 1 for x2, 2 for t)\n",
    "    \"\"\"\n",
    "    grad = torch.autograd.grad(\n",
    "        outputs = y,\n",
    "        inputs = x,\n",
    "        grad_outputs=torch.ones_like(y),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, idx]  # shape (N, 3)\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc602e7",
   "metadata": {},
   "source": [
    "### Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2076ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_physics(model, x):\n",
    "    \"\"\"\n",
    "    Residual loss coming from the PDE\n",
    "    Input:\n",
    "        model: PINN model\n",
    "        x: input tensor of shape (N, 3)\n",
    "    Output:\n",
    "        loss: scalar tensor\n",
    "    \"\"\"\n",
    "    u = model(x)\n",
    "\n",
    "    # first derivatives\n",
    "    grads = get_gradients(model, x)  # shape (N, 2, 3)\n",
    "    dx1 = grads[:, :, 0]  # shape (N, 2) because of Real and Imaginary parts\n",
    "    dx2 = grads[:, :, 1]  # shape (N, 2)\n",
    "    dt = grads[:, :, 2]  # shape (N, 2)\n",
    "\n",
    "\n",
    "    # get the second derivatives for the laplacian, real and imaginary parts\n",
    "    u_r_x1 = dx1[:, 0]  # Real part gradient w.r.t x1\n",
    "    u_r_x2 = dx2[:, 0]  # Real part gradient w.r\n",
    "    u_r_x1x1 = second_derivative(u_r_x1, x, 0)\n",
    "    u_r_x2x2 = second_derivative(u_r_x2, x, 1)\n",
    "    lap_u_r = u_r_x1x1 + u_r_x2x2  # Laplacian of the real part\n",
    "\n",
    "    u_i_x1 = dx1[:, 1]  # Imaginary part gradient w.r.t x1\n",
    "    u_i_x2 = dx2[:, 1]  # Imaginary part gradient w.r\n",
    "    u_i_x1x1 = second_derivative(u_i_x1, x, 0)\n",
    "    u_i_x2x2 = second_derivative(u_i_x2, x, 1)\n",
    "    lap_u_i = u_i_x1x1 + u_i_x2x2  # Laplacian of the imaginary part\n",
    "\n",
    "    # time derivatives in real and imaginary parts\n",
    "    u_r_t = dt[:, 0]  # Real part time derivative\n",
    "    u_i_t = dt[:, 1]  # Imaginary part time derivative\n",
    "\n",
    "\n",
    "    # Residuals for the PDE in real and imaginary parts\n",
    "    res_real = -u_i_t + lap_u_r  # Residual for the real part\n",
    "    res_imag = u_r_t + lap_u_i  # Residual for the imaginary part\n",
    "\n",
    "    # Compute the loss as the mean squared error, |z|^2 = Re(z)^2 + Im(z)^2\n",
    "    loss = torch.mean(res_real**2 + res_imag**2)  # Mean squared error of the residuals\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def loss_boundary(model, x_b):\n",
    "    \"\"\"\n",
    "    Boundary loss for the PINN.\n",
    "    Input:\n",
    "        model: PINN model\n",
    "        x_b: input tensor of boundary points and t>0, shape (N, 3)\n",
    "    Output:\n",
    "        loss: scalar tensor\n",
    "    \"\"\"\n",
    "    u_b = model(x_b)  # shape (N, 2)\n",
    "    \n",
    "    # Boundary condition: u(x1, x2, t) = 0 on the boundary\n",
    "    loss = torch.mean(u_b[:, 0]**2 + u_b[:, 1]**2)  # Mean squared error of the boundary condition\n",
    "    return loss\n",
    "\n",
    "def loss_initial(model, x_i):\n",
    "    \"\"\" \n",
    "    Initial condition loss for the PINN.\n",
    "    u(x1, x2, 0) = sin(pi*x1) * sin(pi*x2)\n",
    "    Input:\n",
    "        model: PINN model\n",
    "        x_i: input tensor of initial points at t=0, shape (N, 3)\n",
    "    Output:\n",
    "        loss: scalar tensor\n",
    "    \"\"\"\n",
    "    u_i = model(x_i)  # shape (N, 2)\n",
    "    \n",
    "    initial_r = torch.sin(np.pi * x_i[:, 0]) * torch.sin(np.pi * x_i[:, 1])  # Real part of initial condition\n",
    "    initial_i = torch.zeros_like(initial_r)  # Imaginary part of initial condition is zero\n",
    "\n",
    "    # residuals\n",
    "    res_r = u_i[:, 0] - initial_r  # Residual for the real part\n",
    "    res_i = u_i[:, 1] - initial_i  # Residual for the imaginary part\n",
    "\n",
    "    # print(\"real loss:\", torch.mean(res_r**2).item(), \"imaginary loss:\", torch.mean(res_i**2).item())\n",
    "    # compute the loss as the mean squared error\n",
    "    loss = torch.mean(res_r**2 + res_i**2)  # Mean squared error of the initial condition\n",
    "\n",
    "    return loss\n",
    "\n",
    "def total_loss(model, x_b, x_i, x_pde):\n",
    "    \"\"\"\n",
    "    Total loss function combining boundary, initial, and PDE losses.\n",
    "    Input:\n",
    "        model: PINN model\n",
    "        x_b: boundary points\n",
    "        x_i: initial points\n",
    "        x_pde: PDE points\n",
    "    Output:\n",
    "        total_loss: scalar tensor\n",
    "    \"\"\"\n",
    "\n",
    "    lambda_bc = 1.0  # Weight for boundary loss\n",
    "    lambda_ic = 1.0  # Weight for initial condition loss\n",
    "    lambda_pde = 1.0  # Weight for PDE loss\n",
    "    \n",
    "    loss_bc = loss_boundary(model, x_b)  # Boundary loss\n",
    "    loss_ic = loss_initial(model, x_i)  # Initial condition loss\n",
    "    loss_pde = loss_physics(model, x_pde)  # PDE loss\n",
    "\n",
    "    total_loss = lambda_bc * loss_bc + lambda_ic * loss_ic + lambda_pde * loss_pde  # Combine losses\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e844f54",
   "metadata": {},
   "source": [
    "### Train the model:\n",
    "\n",
    "Functions for sampling points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90721a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample points for the boundary and initial conditions\n",
    "T = 0.1\n",
    "\n",
    "\n",
    "def sample_boundary_points(num_points, T=0.1):\n",
    "    \"\"\"\n",
    "    Sample points on the boundary of the domain [0,1]^2.\n",
    "    Output: tensor of shape (num_points, 3)\n",
    "    \"\"\"\n",
    "    x1 = np.zeros(num_points)\n",
    "    x2 = np.zeros(num_points)\n",
    "    t = np.random.uniform(0.01, T, num_points)\n",
    "\n",
    "    # Divide points equally among the four edges\n",
    "    num_per_edge = num_points // 4\n",
    "\n",
    "    # x1 = 0, x2 in [0,1]\n",
    "    x1[:num_per_edge] = 0.0\n",
    "    x2[:num_per_edge] = np.random.uniform(0, 1, num_per_edge)\n",
    "\n",
    "    # x1 = 1, x2 in [0,1]\n",
    "    x1[num_per_edge:2*num_per_edge] = 1.0\n",
    "    x2[num_per_edge:2*num_per_edge] = np.random.uniform(0, 1, num_per_edge)\n",
    "\n",
    "    # x2 = 0, x1 in [0,1]\n",
    "    x1[2*num_per_edge:3*num_per_edge] = np.random.uniform(0, 1, num_per_edge)\n",
    "    x2[2*num_per_edge:3*num_per_edge] = 0.0\n",
    "\n",
    "    # x2 = 1, x1 in [0,1]\n",
    "    x1[3*num_per_edge:] = np.random.uniform(0, 1, num_points - 3*num_per_edge)\n",
    "    x2[3*num_per_edge:] = 1.0\n",
    "\n",
    "    x_b = np.column_stack((x1, x2, t))\n",
    "    return torch.tensor(x_b, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "def sample_initial_points(num_points):\n",
    "    \"\"\"\n",
    "    Sample points at the initial time t=0.\n",
    "    Input:\n",
    "        num_points: number of points to sample\n",
    "    Output:\n",
    "        x_i: tensor of shape (num_points, 3) containing sampled points\n",
    "    \"\"\"\n",
    "    x1 = np.random.uniform(0, 1, num_points)\n",
    "    x2 = np.random.uniform(0, 1, num_points)\n",
    "    t = np.zeros(num_points)  # t = 0\n",
    "    x_i = np.column_stack((x1, x2, t))\n",
    "    return torch.tensor(x_i, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def sample_interior_points(num_points, T = 0.1):\n",
    "    \"\"\"\n",
    "    Sample points in the interior of the domain.\n",
    "    Input:\n",
    "        num_points: number of points to sample\n",
    "    Output:\n",
    "        x_i: tensor of shape (num_points, 3) containing sampled points\n",
    "    \"\"\"\n",
    "    x1 = np.random.uniform(0, 1, num_points)\n",
    "    x2 = np.random.uniform(0, 1, num_points)\n",
    "    t = np.random.uniform(0, T, num_points)  # t in [0, T]\n",
    "    x_i = np.column_stack((x1, x2, t))\n",
    "    return torch.tensor(x_i, dtype=torch.float32, requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269706cb",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.19159790873527527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = PINN(n_hidden = 128)\n",
    "\n",
    "N_points = 15000  # Number of points for boundary, initial, and PDE sampling\n",
    "x_b = sample_boundary_points(N_points, T)  # Sample boundary points\n",
    "x_i = sample_initial_points(N_points)  # Sample initial points\n",
    "x_pde = sample_interior_points(N_points, T)  # Sample PDE points\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.001,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=0,\n",
    "    amsgrad=False\n",
    ")\n",
    "\n",
    "epochs = 10000\n",
    "loss_history = []\n",
    "epoch_history = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = total_loss(model, x_b, x_i, x_pde)  # Compute total loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update model parameters\n",
    "    if epoch % 100 == 0:\n",
    "        loss_history.append(loss.item())  # Store loss for plotting\n",
    "        epoch_history.append(epoch)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")  # Print loss every 100 epochs\n",
    "\n",
    "# print all different losses\n",
    "print(f\"Boundary Loss: {loss_boundary(model, x_b).item()}\")\n",
    "print(f\"Initial Condition Loss: {loss_initial(model, x_i).item()}\")\n",
    "print(f\"PDE Loss: {loss_physics(model, x_pde).item()}\")\n",
    "\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(epoch_history, loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1fee1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary Loss: 0.013711050152778625\n",
      "real loss: 0.01003488339483738 imaginary loss: 0.0021358083467930555\n",
      "Initial Condition Loss: 0.012170691974461079\n",
      "PDE Loss: 0.003943736664950848\n"
     ]
    }
   ],
   "source": [
    "# print all different losses\n",
    "print(f\"Boundary Loss: {loss_boundary(model, x_b).item()}\")\n",
    "print(f\"Initial Condition Loss: {loss_initial(model, x_i).item()}\")\n",
    "print(f\"PDE Loss: {loss_physics(model, x_pde).item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12759341",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     35\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 37\u001b[0m plot_model_output(\u001b[43mmodel\u001b[49m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Plot at t=0\u001b[39;00m\n\u001b[1;32m     38\u001b[0m plot_model_output(model, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Plot at t=0.1\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the solution\n",
    "\n",
    "def plot_model_output(model, t = 0):\n",
    "    \"\"\"\n",
    "    Plot the model output for a given time t.\n",
    "    Input:\n",
    "        model: PINN model\n",
    "        t: time at which to evaluate the model\n",
    "    \"\"\"\n",
    "    x1 = np.linspace(0, 1, 100)\n",
    "    x2 = np.linspace(0, 1, 100)\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    X = np.column_stack((X1.ravel(), X2.ravel(), np.full(X1.size, t)))  # t is constant for this plot\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, requires_grad=True)\n",
    "    u_pred = model(X_tensor).detach().numpy()  # Get predictions from the model\n",
    "\n",
    "    # Plot the real and imaginary parts of the solution as subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    # Real part\n",
    "    cf1 = axes[0].contourf(X1, X2, u_pred[:, 0].reshape(X1.shape), levels=50, cmap='viridis')\n",
    "    fig.colorbar(cf1, ax=axes[0], label='Real Part of u')\n",
    "    axes[0].set_title(f'Real Part of the Solution at t={t}')\n",
    "    axes[0].set_xlabel('x1')\n",
    "    axes[0].set_ylabel('x2')\n",
    "\n",
    "    # Imaginary part\n",
    "    cf2 = axes[1].contourf(X1, X2, u_pred[:, 1].reshape(X1.shape), levels=50, cmap='viridis')\n",
    "    fig.colorbar(cf2, ax=axes[1], label='Imaginary Part of u')\n",
    "    axes[1].set_title(f'Imaginary Part of the Solution at t={t}')\n",
    "    axes[1].set_xlabel('x1')\n",
    "    axes[1].set_ylabel('x2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_model_output(model, t=0)  # Plot at t=0\n",
    "plot_model_output(model, t=0.1)  # Plot at t=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4c098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolfinx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
